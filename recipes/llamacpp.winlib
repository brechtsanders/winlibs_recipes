export NAME="llama.cpp"
export STATUS=
export URL=https://github.com/ggerganov/llama.cpp
export BASENAME=llamacpp
export DESCRIPTION="Port of Facebook's LLaMA model in C/C++"
export CATEGORY=artificialintelligence
export TYPE=library
#export VERSION=master
#export VERSIONDATE=20230318
#export VERSION=master-cc9cee8
#export VERSIONDATE=20230407
#export VERSION=master-c12b14b
#export VERSIONDATE=20230415
#export VERSION=master-f647ce0
#export VERSIONDATE=20230505
#export VERSION=master-d5b111f
#export VERSIONDATE=20230606
#export VERSION=master-9d23589
#export VERSIONDATE=20230628
#export VERSION=master-81844fb
#export VERSIONDATE=20230803
#export VERSION=b1247
#export VERSIONDATE=20230803
#export VERSION=b1250
#export VERSIONDATE=20230917
#export VERSION=b1266
#export VERSIONDATE=20230921
#export VERSION=b1299
#export VERSIONDATE=20231001
#export VERSION=b1305
#export VERSIONDATE=20231002
#export VERSION=b1520
#export VERSIONDATE=20231117
#export VERSION=b1601
#export VERSIONDATE=20231202
#export VERSION=b1644
#export VERSIONDATE=20231216
#export VERSION=b1645
#export VERSIONDATE=20231217
#export VERSION=b1729
#export VERSIONDATE=20231230
#export VERSION=b1808
#export VERSIONDATE=20240111
#export VERSION=b1833
#export VERSIONDATE=20240112
#export VERSION=b1961
#export VERSIONDATE=20240124
#export VERSION=b1989
#export VERSIONDATE=20240128
export VERSION=b2013
export VERSIONDATE=20240130
wl-showstatus --package-version
export DEPENDENCIES=
export OPTIONALDEPENDENCIES=
export BUILDDEPENDENCIES=cmake,ninja
export OPTIONALBUILDDEPENDENCIES=
export LICENSEFILE=LICENSE
export LICENSETYPE=MIT
export DOWNLOADURL="https://github.com/ggerganov/llama.cpp/tags b"
export INSTALLPREFIX=`pwd`/inst_$BASENAME-$VERSION
#export DOWNLOADSOURCEURL=https://github.com/ggerganov/llama.cpp/archive/refs/heads/$VERSION.tar.gz
export DOWNLOADSOURCEURL=https://github.com/ggerganov/llama.cpp/archive/refs/tags/$VERSION.tar.gz
wl-showstatus download
wl-download -v -d $TARBALLDIR/$BASENAME $DOWNLOADSOURCEURL
wl-wait4deps
wl-showstatus extract
tar xz --force-local -f $TARBALLDIR/$BASENAME/$VERSION.tar.gz
cd llama.cpp-$VERSION
## fix missing PWIN32_MEMORY_RANGE_ENTRY in llama.cpp (version >= b1299 <= b1833)
#mv llama.cpp llama.cpp.bak 
#cat > llama.cpp << EOF
##if !defined(_WIN32_WINNT) || _WIN32_WINNT < 0x0602
##undef _WIN32_WINNT
##define _WIN32_WINNT 0x0602
##endif
#EOF
#cat llama.cpp.bak >> llama.cpp
# missing undeclared FINDEX_INFO_LEVELS (version >= b1961)
for F in $(find -name '*.c' -or -name '*.cpp'); do
mv $F $F.bak 
cat > $F << EOF
#if !defined(_WIN32_WINNT) || _WIN32_WINNT < 0x0602
#undef _WIN32_WINNT
#define _WIN32_WINNT 0x0602
#endif
EOF
cat $F.bak >> $F
done
mkdir -p build_static build_shared &&
 #wl-showstatus configure &&
 #cmake.exe -Wno-dev -GNinja -DCMAKE_INSTALL_PREFIX:PATH=$INSTALLPREFIX/share/llamacpp -DCMAKE_BUILD_TYPE:STRING=Release -DBUILD_SHARED_LIBS:BOOL=OFF -DLLAMA_BUILD_EXAMPLES:BOOL=OFF -DBUILD_TESTING:BOOL=OFF -S. -Bbuild_static &&
 wl-showstatus configure &&
 cmake.exe -Wno-dev -GNinja -DCMAKE_INSTALL_PREFIX:PATH=$INSTALLPREFIX/share/llamacpp -DCMAKE_BUILD_TYPE:STRING=Release -DBUILD_SHARED_LIBS:BOOL=ON -DLLAMA_BUILD_EXAMPLES:BOOL=OFF -DBUILD_TESTING:BOOL=OFF -S. -Bbuild_shared &&
 ## fix empty BUILD_NUMBER (version >= b1299 <= b1305)
 #sed -i.bak -e "s/^#define BUILD_NUMBER\s*$/& 0/" build-info.h &&
 #wl-showstatus build-install &&
 #ninja -Cbuild_static install/strip &&
 wl-showstatus build-install &&
 ninja -Cbuild_shared install/strip &&
 wl-makepackage -c -d && wl-install -d $BASENAME-$VERSION && cd .. && wl-showstatus cleanup && rm -rf llama.cpp-$VERSION
####$MINGWPREFIX/share/llamacpp/bin/llava-cli.exe
####Note: conflicts with / superseded by alpacacpp



