export NAME="llama.cpp"
export STATUS=
export URL=https://github.com/ggerganov/llama.cpp
export BASENAME=llamacpp
export DESCRIPTION="Port of Facebook's LLaMA model in C/C++"
export CATEGORY=artificialintelligence
export TYPE=library
#export VERSION=master
#export VERSIONDATE=20230318
#export VERSION=master-cc9cee8
#export VERSIONDATE=20230407
#export VERSION=master-c12b14b
#export VERSIONDATE=20230415
#export VERSION=master-f647ce0
#export VERSIONDATE=20230505
#export VERSION=master-d5b111f
#export VERSIONDATE=20230606
#export VERSION=master-9d23589
#export VERSIONDATE=20230628
#export VERSION=master-81844fb
#export VERSIONDATE=20230803
#export VERSION=b1247
#export VERSIONDATE=20230803
#export VERSION=b1250
#export VERSIONDATE=20230917
#export VERSION=b1266
#export VERSIONDATE=20230921
#export VERSION=b1299
#export VERSIONDATE=20231001
#export VERSION=b1305
#export VERSIONDATE=20231002
#export VERSION=b1520
#export VERSIONDATE=20231117
#export VERSION=b1601
#export VERSIONDATE=20231202
#export VERSION=b1644
#export VERSIONDATE=20231216
#export VERSION=b1645
#export VERSIONDATE=20231217
#export VERSION=b1729
#export VERSIONDATE=20231230
#export VERSION=b1808
#export VERSIONDATE=20240111
#export VERSION=b1833
#export VERSIONDATE=20240112
#export VERSION=b1961
#export VERSIONDATE=20240124
#export VERSION=b1989
#export VERSIONDATE=20240128
#export VERSION=b2013
#export VERSIONDATE=20240130
#export VERSION=b2050
#export VERSIONDATE=20240203
#export VERSION=b2110
#export VERSIONDATE=20240209
#export VERSION=b2136
#export VERSIONDATE=20240213
#export VERSION=b2137
#export VERSIONDATE=20240217
#export VERSION=b2194
#export VERSIONDATE=20240219
#export VERSION=b2249
#export VERSIONDATE=20240223
#export VERSION=b2297
#export VERSIONDATE=20240301
#export VERSION=b2308
#export VERSIONDATE=20240302
#export VERSION=b2321
#export VERSIONDATE=20240303
#export VERSION=b2352
#export VERSIONDATE=20240306
#export VERSION=b2355
#export VERSIONDATE=20240307
#export VERSION=b2365
#export VERSIONDATE=20240309
#export VERSION=b2409
#export VERSIONDATE=20240313
#export VERSION=b2410
#export VERSIONDATE=20240313
#export VERSION=b2412
#export VERSIONDATE=20240314
#export VERSION=b2418
#export VERSIONDATE=20240314
#export VERSION=b2430
#export VERSIONDATE=20240315
#export VERSION=b2436
#export VERSIONDATE=20240315
#export VERSION=b2440
#export VERSIONDATE=20240316
#export VERSION=b2447
#export VERSIONDATE=20240317
#export VERSION=b2450
#export VERSIONDATE=20240318
#export VERSION=b2456
#export VERSIONDATE=20240318
#export VERSION=b2459
#export VERSIONDATE=20240319
#export VERSION=b2463
#export VERSIONDATE=20240319
#export VERSION=b2465
#export VERSIONDATE=20240320
#export VERSION=b2487
#export VERSIONDATE=20240322
export VERSION=b2496
export VERSIONDATE=20240322
wl-showstatus --package-version
export DEPENDENCIES=
export OPTIONALDEPENDENCIES=
export BUILDDEPENDENCIES=cmake,ninja
export OPTIONALBUILDDEPENDENCIES=
export LICENSEFILE=LICENSE
export LICENSETYPE=MIT
export DOWNLOADURL="https://github.com/ggerganov/llama.cpp/tags b"
export INSTALLPREFIX=`pwd`/inst_$BASENAME-$VERSION
#export DOWNLOADSOURCEURL=https://github.com/ggerganov/llama.cpp/archive/refs/heads/$VERSION.tar.gz
export DOWNLOADSOURCEURL=https://github.com/ggerganov/llama.cpp/archive/refs/tags/$VERSION.tar.gz
wl-showstatus download
wl-download -v -d $TARBALLDIR/$BASENAME $DOWNLOADSOURCEURL
wl-wait4deps
wl-showstatus extract
tar xz --force-local -f $TARBALLDIR/$BASENAME/$VERSION.tar.gz
cd llama.cpp-$VERSION
## fix missing PWIN32_MEMORY_RANGE_ENTRY in llama.cpp (version >= b1299 <= b1833)
#mv llama.cpp llama.cpp.bak 
#cat > llama.cpp << EOF
##if !defined(_WIN32_WINNT) || _WIN32_WINNT < 0x0602
##undef _WIN32_WINNT
##define _WIN32_WINNT 0x0602
##endif
#EOF
#cat llama.cpp.bak >> llama.cpp
## missing undeclared FINDEX_INFO_LEVELS (version >= b1961 <= b2365)
#for F in $(find -name '*.c' -or -name '*.cpp'); do
#mv $F $F.bak 
#cat > $F << EOF
##if !defined(_WIN32_WINNT) || _WIN32_WINNT < 0x0602
##undef _WIN32_WINNT
##define _WIN32_WINNT 0x0602
##endif
#EOF
#cat $F.bak >> $F
#done
# missing undeclared FINDEX_INFO_LEVELS (version >= b2409)
sed -i.bak -e "1s/^\(.*\)\(#include\)/\1#if \!defined(_WIN32_WINNT) || _WIN32_WINNT < 0x0602\n#undef _WIN32_WINNT\n#define _WIN32_WINNT 0x0602\n#endif\n\2/" $(find -name '*.c' -or -name '*.cpp')
# fix undefined uint8_t in unicode.cpp (version >= b2406)
sed -i.bak2 -e "1s/^\(.*\)\(#include\)/\1#include <cstdint>\n\2/" unicode.cpp
mkdir -p build_static build_shared &&
 #wl-showstatus configure &&
 #cmake.exe -Wno-dev -GNinja -DCMAKE_INSTALL_PREFIX:PATH=$INSTALLPREFIX/share/llamacpp -DCMAKE_BUILD_TYPE:STRING=Release -DBUILD_SHARED_LIBS:BOOL=OFF -DLLAMA_BUILD_EXAMPLES:BOOL=OFF -DBUILD_TESTING:BOOL=OFF -S. -Bbuild_static &&
 wl-showstatus configure &&
 cmake.exe -Wno-dev -GNinja -DCMAKE_INSTALL_PREFIX:PATH=$INSTALLPREFIX/share/llamacpp -DCMAKE_BUILD_TYPE:STRING=Release -DBUILD_SHARED_LIBS:BOOL=ON -DLLAMA_BUILD_EXAMPLES:BOOL=OFF -DBUILD_TESTING:BOOL=OFF -S. -Bbuild_shared &&
 ## fix empty BUILD_NUMBER (version >= b1299 <= b1305)
 #sed -i.bak -e "s/^#define BUILD_NUMBER\s*$/& 0/" build-info.h &&
 #wl-showstatus build-install &&
 #ninja -Cbuild_static install/strip &&
 wl-showstatus build-install &&
 ninja -Cbuild_shared install/strip &&
 wl-makepackage -c -d && wl-install -d $BASENAME-$VERSION && cd .. && wl-showstatus cleanup && rm -rf llama.cpp-$VERSION
####$MINGWPREFIX/share/llamacpp/bin/llava-cli.exe
####Note: conflicts with / superseded by alpacacpp



